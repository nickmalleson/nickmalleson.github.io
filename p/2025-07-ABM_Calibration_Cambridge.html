<!doctype html>
<html>

    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
        <meta name="author" content="Nick Malleson">
        <meta name="keywords" content="digital twins, ABM, data assimilation, city simulation, particle filter, uncertainty">

        <title>Data Assimilation for Agent-Based Models</title>

        <link rel="stylesheet" href="reveal/css/reveal.css">
        <link rel="stylesheet" href="reveal/css/theme/white.css">

        <!-- Some extra bits added by Nick -->
        <link rel="stylesheet" href="reveal/css/nick.css">

        <!-- Theme used for syntax highlighting of code -->
        <link rel="stylesheet" href="reveal/lib/css/zenburn.css">
        
        <!-- For the EnKF formula -->
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script type="text/javascript" async
                src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
        </script>

        <!-- Pr,inting and PDF exports -->
        <script>
            var link = document.createElement('link');
            link.rel = 'stylesheet';
            link.type = 'text/css';
            link.href = window.location.search.match(/print-pdf/gi) ? 'reveal/css/print/pdf.css' : 'reveal/css/print/paper.css';
            document.getElementsByTagName('head')[0].appendChild(link);
        </script>
    </head>

    <body>
        <div class="reveal">
            <div class="slides">

                <section class="title" id="index"
                         data-background-video="../videos/city_night.mp4"
                         data-background-video-loop="loop">
                    <div class="whitebackground2">
                        <h5>Calibration of Agent-Based Models. 11th July 2025, Cambridge.</h5>
                        <hr />
                        <h1 style="font-size: 45px;">Data Assimilation for Agent-Based Models<br/> 
                            <div style="font-size: 35px;">(With a sprinkling of ABC and LLMs)</div></h1>
                        <hr />
                        <h2 style="font-size: 25px;">
                            <a href="http://nickmalleson.co.uk/">Nick Malleson</a>, University of Leeds, UK</h2>
                        <!--<h4><a href="mailto:n.s.malleson@leeds.ac.uk">n.s.malleson@leeds.ac.uk</a>-->
                        <!--<h4><a href="http://dust.leeds.ac.uk">dust.leeds.ac.uk</a></h4>-->
                        <hr />
                        <p style="text-align:center;font-size:20px">Slides available at: <br />
                            <a href="https://urban-analytics.github.io/dust/presentations.html">https://urban-analytics.github.io/dust/presentations.html</a>
                        </p>
                        <hr />
                        <a href="https://europa.eu/european-union/index_en">
                            <img style="float:left;padding:5px;width:auto; height:60px;"
                                 data-src="../figures/LOGO_EU.jpg" />
                        </a>
                        <a href="http://www.leeds.ac.uk/">
                            <img style="float:right;padding:5px;width:auto; height:60px;"
                                 data-src="../figures/uol_logo.gif" />
                        </a>
                        <!--<a href="https://environment.leeds.ac.uk/geography">
<img style="float:right;padding:10px;width:150px; height:auto;" data-src="../figures/LOGO_SOG.png" />
</a>-->
                        <!-- <a href="http://www.turing.ac.uk/">
<img style="float:right;padding:10px;width:150px; height:auto;" src="../figures/LOGO_TURING.png"/>
</a> -->
                    </div>
                </section>
                
                <section id="outline">
                    
                    <img src="../figures/chatgpt/digital_city_abm.png" class="right"
                         style="width:30%;"
                         alt="Nice sunset/sunrise" />
                    <h2>Outline</h2>
                    <p>Dynamic re-calibration of a COVID-19 ABM using Approximate Bayesian Computation</p>
                    <p>Data assimilation for ABMs using Particle Filters and Kalman Filters</p>
                    <p>For desert: LLM-backed ABMs</p>
                </section>
                
                
                
                <!-- ************************************************************
                    ************************** DYME *****************************
                    ************************************************************ -->
                
                
                <section id="progress-model_synthesis-dyme">
                    <figure class="right">
                        <img src="../figures/paper_figures/2021-03-RAMP/RAMP_Workflow-with_GeoLytics.png"
                             alt="Diagram of the ramp model components described in the slide text" />
                        <figcaption>Spooner et al. (2021) A dynamic microsimulation model for epidemics. <em>Social Science &amp; Medicine</em> 291, 114461. DOI: <a href="https://doi.org/10.1016/j.socscimed.2021.114461">10.1016/j.socscimed.2021.114461</a></figcaption>
                    </figure>
                    <h2>Model synthesis</h2>
                    <h3>DyME: Dynamic Model for Epidemics</h3>
                    <!--<p>Part of the Royal Society Rapid Assistance in Modelling the Pandemic (RAMP) call</p>-->
                    <p>COVID transmission model with components including:</p>
                    <p class="l2">dynamic spatial microsimulation, spatial interaction model, data linkage (PSM), ...</p> 
                    <p>Represents all individuals in a study area with activities: home, shopping, working, schooling</p>
                    <p>Daily timestep</p>

                </section>
                
                
                <section id="progress-model_synthesis-dyme-method">
                    <img data-src="../figures/paper_figures/2021-03-RAMP/Dynamic_Workflow.png" 
                         alt="Figure illustrates the process of COVID spreading as people visit places"/>
                </section>
                
                <section id="progress-model_synthesis-dyme-results">
                    
                    <img data-src="../figures/paper_figures/2021-03-RAMP/week_earlier_scenario.png"
                         att="Results of the model suggest that there would have been 50% fewer COVID cases"/>
                    
                    <aside class="notes">
                        "For the baseline scenario daily infections peaks at 763 (266–1047, 95% CI) people per day, while the experimental (i.e. lockdown one week earlier) scenario shows a peak of 556 (137–718, 95% CI) people per day"
                        
                        This is am average 54% decrease across all age groups.
                    </aside>
                    
                </section>
                
                
                <section id="progress-model_synthesis-dyme-data">
                    <h2>DyME Drawbacks: Data and Latent Variables</h2>
                    <p>Incredible detailed model!</p>
                    <p>BUT only data available for validation: COVID cases and hospital deaths</p>
                    <p class="l2">Only quantify a tiny part of the transmission dynamics</p>
                    <p class="l2">Huge uncertainties</p>
                    <p>Can we use dynamic calibration to:</p>
                    <p class="l2">Infer latent variables</p>
                    <p class="l2">Make better 'real-time' predictions</p>
                    
                    <!--<img data-src="../figures/paper_figures/2021-03-RAMP/Disease_Status_Upates.png"
                         style="width:80%;"
                         alt="Different disease stages: susceptible, exposed (pre)(a)symptomatic, removed" />-->
                </section>
                
                <section id='dyme-dynamic_calibration'>
                    <h2>Dynamic Calibration for DyME</h2>
                    <p>Use Approximate Bayesian Computation and Bayesian updating ('dynamic re-calibration')</p>
                    <figure >
                        <img data-src="../figures/paper_figures/2022-RAMP_DA/model_workflow3.png"
                         alt="Bayesian updating of the DyME model. The parameter posteriors from one window are
                              used as priors in the next window"/>

                    </figure>
                    <p class="l2">Reduce uncertainty and produce more accurate future predictions</p>
                    <p class="l2">Parameter posteriors might reveal information about the model / system</p>
                </section>

                <section id='dyme-abc-posteriors'>
                    <figure>
                        <img data-src="../figures/paper_figures/2022-RAMP_DA/parameter_evolution.png"
                             style="width: 70%;"
                            alt="Posterior parameter estimates for the DyME model"/>
                        <figcaption>
                            M. Asher, N. Lomax, K. Morrissey, F. Spooner, N. Malleson (2023) Dynamic Calibration with Approximate Bayesian Computation for a Microsimulation of Disease Spread. <i>Nature Scientific Reports</i> (under review)
                        </figcaption>
                    </figure>
                </section>

                <section id='dyme-abc-predictions'>
                    <figure>
                        <img data-src="../figures/paper_figures/2022-RAMP_DA/model_predictions.png"
                             alt="Uncertain predictions made using the DyME parameter posteriors.
                                  The certainty increases as more data become available."/>
                        <figcaption>
                            M. Asher, N. Lomax, K. Morrissey, F. Spooner, N. Malleson (2023) Dynamic Calibration with Approximate Bayesian Computation for a Microsimulation of Disease Spread. <i>Nature Scientific Reports</i> (under review)
                        </figcaption>
                    </figure>
                </section>
                    
                
                <section id="progress-computation-dyme">
                    
                    <h2>Aside: Computational Efficiency</h2>
                    <p>Uncertainty quantification, etc., requires many, many model runs</p>
                    <p>Difficult with computationally-expensive models, like ABMs</p>
                    <figure class="right">
                        <img  data-src="../figures/ramp/ramp_gui_1.png" alt="Screenshot of the RAMP GUI" />
                        <!--<img  data-src="../figures/ramp/ramp_gui_2.png" alt="Screenshot of the RAMP GUI" /> -->
                    </figure>
                    <p>DyME (COVID microsimulation)</p>
                    <p class="l2">A single model run (800,000 individuals, 90 days) took 2 hours</p>
                    <p class="l2">ABC etc. would be impossible at that speed (need 1000s of runs)</p>
                    <p class="l2">Big computers can help</p>
                    <p class="l2">But maybe if I were better at programming ...</p>
                </section>
                
                <section id="progress-computation-dyme-improbable"
                         data-background-video="../videos/Ramp_UA_2020-08-28 12-29-25.mp4">
                    <div class="whitebackground2 fragment">
                        <img src="../figures/LOGO_Improbable.png" class="right" style="width:30%;"
                             alt="Improbable company logo" />
                        <p>Re-implemented numpy/pandas model using (py)OpenCL</p>
                        <p>Run time went from 2 hours to a few seconds!</p>
                        <p>Transforms the potential uses of the model</p>
                    </div>
                
                </section>
                
                
                
                
                <!-- ************************************************************
                    ******************* DATA ASSIMILATION ***********************
                    ************************************************************ -->

                <section id="prob-divergence" data-background-video="../videos/starlings1-short.mp4"
                         data-background-video-muted data-background-video-loop="loop">

                    <div class="whitebackground fragment">
                        <h2>Why we need Data Assimilation</h2>
                        <p>Complex models will always diverge</p>
                        <p class="l2">(due to inherent uncertainties in inputs, parameter values, model structure, etc.)</p>
                        <p>Possible Solution: Data Assimilation</p>
                        <p>Used in meteorology and hydrology to bring models closer to reality. Combines:</p>
                        <p class="l2">Noisy, real-world observations</p>
                        <p class="l2">Model estimates of the system state</p>
                    </div>
                </section>

                <section id="dda-vs-calibration">

                    <h2>Data assimilation v.s. calibration</h2>

                    <img data-src="../figures/data-assimilation2.png" style="width:70%;"
                         alt="Example of optimising the model state using observations and data assimilation"/>

                </section>


                <!--<section id="abm-dda-overview">
                    <img data-src="../figures/paper_figures/dda.jpg" alt="Diagram of data assimilation and an ABM" />
                </section>-->


                <section id="da-challenges">

                    <h2>Challenges for using DA with ABMs</h2>

                    <p>Model size</p>
                    <p class="l2">10,000 agents * 5 variables = 50,000 distinct parameters</p>
                    <p>Agent behaviour</p>
                    <p class="l2">Agent's have goals, needs, etc., so can't be arbitrarily adjusted</p>
                    <p>Assumptions and parameter types</p>
                    <p class="l2">Maths typically developed for continuous parameters and 
                        assume normal distributions</p>
                    <p>... but, at least, many of these problems are shared by climate models</p>

                </section>


                <!-- ************************************************************
                    *************************  PARTICLE FILTER **********************
                    ************************************************************ -->

                <section id="pf-experiments">
                    <h2>Data assimilation with a Particle Filter</h2>
                    <img data-src="../figures/PF_flowchart3.png"
                         alt="Flowchart of the experimental design. Lots of models ('particles') are run simultaneously." />
                </section>

                <!--<section id="pf-station-experiments">
                    <h3>Particle Filter &amp; Crowd Simulation</h3>
                    <img style="width:80%" data-src="../figures/pf_overview.png" alt="Station PF experimental design." />
                </section> -->

                <section id="pf-stationsim2-b" data-transition="fade">
                    <h2>Crowd Simulation with a Particle Filter</h2>
                    <img data-src="../figures/pf_animation.gif"
                         alt="Animation of a crowding model with data assimilation" />
                </section>

                <section id="pf-results-median_error">

                    <h2>Particle Filter Results</h2>
                    <p>Box Environment: More particles = lower error</p>
                    <p>Exponential increase in complexity</p>
                    <figure>
                        <img style="width:60%"
                             data-src="../figures/paper_figures/2018-ParticleFilterFigs/median_abs_error.png" 
                             alt="median absolute error change with number of agents and particles: greater
                                  complexity caused by larger numbers of agents can be mitigated by increasing
                                  the numbers of particles." />
                    </figure>
                    <figcaption>
                        Malleson, Nick, Kevin Minors, Le-Minh Kieu, Jonathan A. Ward, Andrew West, and Alison Heppenstall.
                        (2020) Simulating Crowds in Real Time with Agent-Based Modelling and a Particle Filter. <i>Journal
                        of Artificial Societies and Social Simulation</i> 23(3) DOI: 
                        <a href="https://doi.org/10.18564/jasss.4266">10.18564/jasss.4266</a>.
                    </figcaption>
                </section>
                
                
                <!--<section id="pf-results-wiggle-count">
                    <h2>Difficulties (I)</h2>
                    <h3>Exponential increase in complexity</h3>
                    <figure>
                        <img style="width:60%;" data-src="../figures/paper_figures/2018-ParticleFilterFigs/wiggle_count.png"
                             alt="Number of collisions increases exponentially with number of agents" />
                        <figcaption>
                            N. Malleson, K. Minors, Le-Minh Kieu, J. A. Ward, A. West and Alison Heppenstall (2020).
                            Simulating Crowds in Real Time with Agent-Based Modelling and a Particle Filter.
                            <i>Journal of Artificial Societies and Social Simulation (JASSS)</i>
                            <a href="http://jasss.soc.surrey.ac.uk/23/3/3.html">23(3), 3</a>.
                        </figcaption>
                    </figure>
                </section> -->
                
                <!-- ************************************************************
                    *******************************  UKF  ***********************
                    ************************************************************* -->
                
                <!-- UKF
                <section id="ukf">
                    <h2>Other DA methods (i)</h2>
                    <h3>Unscented Kalman Filter (UKF)</h3>
                    <p>Similar to the (very popular) Ensemble Kalman filter</p>
                    <p class="l2">Should be more efficient</p>
                    <p class="l2">But assumes Gaussian distributions</p>
                    <p>A few <i>sigma points</i> are chosen to represent the model state</p>
                    <p>Then some complicated maths happens ... </p>
                </section>

                <section id="ukf-results1">
                    <h3>Unscented Kalman Filter (UKF)</h3>
                    <p>Observe a proportion of the agents</p>
                    <figure>
                        <img style="width:70%;" data-src="../figures/paper_figures/2019-UKF/ukf_pairs050.png" 
                             alt="Results of the UKF. Most agent positions are estimated reasonably well."/>
                        <figcaption>Clay, Robert, J. A. Ward, P. Ternes, Le-Minh Kieu, N. Malleson (2021) Real-time agent-based crowd simulation with the Reversible Jump Unscented Kalman Filter. <i>Simulation Modelling Practice and Theory</i> 113 (102386) DOI: <a href="https://dx.doi.org/10.1016/j.simpat.2021.102386">10.1016/j.simpat.2021.102386</a></figcaption>
                    </figure>
                </section>
                
                <section id="ukf-results2">
                    <h3>Unscented Kalman Filter (UKF)</h3>
                    <p>Observed v.s. Unobserved agents</p>
                    <figure>
                        <img class="left" data-src="../figures/paper_figures/2019-UKF/Mixed_Choropleth.png" />
                        <img class="right" data-src="../figures/paper_figures/2019-UKF/Unobserved_Choropleth.png" 
                             alt="Results of the UKF (2). For agents who we have no information about ('unobserved'),
                                  the algorithm is sometimes able to infer their behaviour from that of agents
                                  who we do have information about."/>
                        <figcaption>Clay, Robert, J. A. Ward, P. Ternes, Le-Minh Kieu, N. Malleson (2021) Real-time agent-based crowd simulation with the Reversible Jump Unscented Kalman Filter. <i>Simulation Modelling Practice and Theory</i> 113 (102386) DOI: <a href="https://dx.doi.org/10.1016/j.simpat.2021.102386">10.1016/j.simpat.2021.102386</a></figcaption>
                    </figure>
                </section>-->
                
                
                <!-- ***********************************************************
                    *******************  Grand Central Station *****************
                    ************************************************************ -->

                <section id="gcs" data-background-video="../videos/grandcentral-short.mp4" data-background-video-muted
                         data-background-video-loop="loop">

                    <div class="whitebackground2 fragment">
                        <h2>More realistic simulations:<br/>Grand Central Terminal (New York)</h2>

                        <p>Pedestrian traces data</p>
                        <p>B. Zhou, X. Wang and X. Tang. (2012) Understanding Collective Crowd Behaviors:
                            Learning a Mixture Model of Dynamic Pedestrian-Agents. In <i>Proceedings of IEEE Conference on
                            Computer Vision and Pattern Recognition (CVPR)</i> 2012</p>
                        <p class="l2"><a href="http://www.ee.cuhk.edu.hk/~xgwang/grandcentral.html">
                            http://www.ee.cuhk.edu.hk/~xgwang/grandcentral.html</a></p>
                        <p>Cleaned and prepared by <a href="https://doi.org/10.12688/openreseurope.14144.1">Ternes et al. (2021)</a>.</p>


                        <!--
                        <img class="left" , style="width:50%"
                             data-src="../figures/paper_figures/2020-PhilTrans-GrandCentralStation/grand_central_floorplan.png"
                             alt="Grand Central Terminal floor plan with entrances around the sides and an obstruction in the centre." />

                        <img class="right" style="width:30%"
                             data-src="../figures/paper_figures/2020-PhilTrans-GrandCentralStation/trajectories-structure.png"
                             alt="Pedestrian trajectories estimated from the video" />
                        -->

                    </div>
                </section>
                
                 <!-- ************************************************************
                    ************************* EnKF  ************************
                    ************************************************************ -->
                
                <section id="enkf">
                    <h2>Ensemble Kalman Filter (EnKF)</h2>
                    <p>More complicated, and has stronger assuptions, but can update the model state (including categorical parameters) directly</p>
                    <p>
                            \( \hat{X} = X + K \left( D - H X \right) \)
                    </p>
                    <p class="l2">Current state estimate (\(X\)) updated with new information (\(\hat{X}\))</p>
                    <p class="l2">\(K\) (Kalman gain) balances importance of new data (\(D\)) v.s. current prediction.</p>
                    <p class="l2">\(H X\): prediction transformed into the same space as the observed data 
                    (e.g. arrregate observations and individual agents)</p> 
                    <p>Challenges:</p>
                    <p class="l2">Designed for continuous data -- categorical parameters need converting (non trivial)</p>
                    <p class="l2">Unpredictable human behaviour</p>
                    <p class="l2">Problems with numeric scales (struggles with large and small numbers)
                </section>
                
                
                
                <section id="enkf_results">
                    <h2>EnKF for Pedestrian Simulation</h2>
                    <figure class="left" style="width:50%;">
                        <img data-src="../figures/paper_figures/2023-EnKF_Location_Estimation/updating_state2.png" 
                             alt="Figure illustrates that, after DA, the posterior estimates of two agents' locations are much closer to their corresponding positions in the data (observation)" />
                        <figcaption>Figure 9: Comparison of prior and posterior positions of
                            two agents (‘A’ and ‘B’) in all ensemble member models. After DA the positional estimates of
                        the agents' locations are much more accurate and have lower variability.</figcaption>
                    </figure>
                    <figure class="right" style="width:35%;">
                        <img data-src="../figures/paper_figures/2023-EnKF_Location_Estimation/cover.png"
                             alt="Front page of the published paper" />
                        <figcaption style="font-size: small">Suchak, K., M. Kieu, Y. Oswald, J. A. Ward, and N. Malleson (2024), 
                            Coupling an Agent-Based Model and an Ensemble Kalman Filter for Real-Time Crowd Modelling. 
                            <em>Royal Society Open Science 11</em> (4): 231553. 
                            DOI: <a href="https://doi.org/10.1098/rsos.231553">10.1098/rsos.231553</a>.</figcaption>
                    </figure>


                </section>

                <section id="enkf_results-interactive">
                    <iframe width="1200" height="1000" src="../other/enkf_animation.html"
                            title="Ensemble Kalman Filter"></iframe>

                </section>
                
                
                
                <!-- ************************************************************
                ******************* International Policy Diffusion *****************************
                ************************************************************ -->
                
                <section id="PolicyDiffusion-Overview" >
                    <figure class="right">
                        <img data-src="../figures/paper_figures/2023-Covid_Policy_Response/cover.png"
                         alt="Cover image of the paper" />
                        <!--<figcaption><p style="font-size: smaller">Y. Oswald, N. Malleson and K. Suchak (2024). 
                        An Agent-Based Model of the 2020 International Policy Diffusion in Response to the 
                        COVID-19 Pandemic with Particle Filter.
                        <i>Journal of Artificial Societies and Social Simulation</i> 27(2) 3. DOI: 
                        <a href="https://dx.doi.org/10.18564/jasss.5342">10.18564/jasss.5342</a></p></figcaption>-->
                    </figure>
                    <h2>Case Study 2:</h2>
                    <h3>International Policy Diffusion</h3>
                    <p>ABM simulates COVID-19 policy diffusion via peer mimicry</p>
                    <p>Particle filter enhances prediction accuracy with real-time data.</p>
                    <p>Frequent filtering improves results.</p>
                    <p>&nbsp;</p>
                    <p style="font-size: small">Y. Oswald, N. Malleson and K. Suchak (2024). 
                        An Agent-Based Model of the 2020 International Policy Diffusion in Response to the 
                        COVID-19 Pandemic with Particle Filter.
                        <i>Journal of Artificial Societies and Social Simulation</i> 27(2) 3. DOI: 
                        <a href="https://dx.doi.org/10.18564/jasss.5342">10.18564/jasss.5342</a></p>
                </section>
                
                <section id="PolicyDiffusion-Intro" >
                    
                    <figure class="right" >
                        <img src="../figures/paper_figures/2023-Covid_Policy_Response/data_properties-vertical.png"
                             alt="Two subplots showing the progression of COVID-19 policy adoption across countries in March 2020. Panel (a) depicts the number of countries implementing school closures at four levels of stringency (level 0 to level 3) over time, with a rapid transition to level 3 (complete school closures) around mid-March. Panel (b) compares the adoption of various policies, including school closures, workplace closures, event cancellations, stay-at-home orders, domestic travel restrictions, and international travel restrictions, all measured by the number of countries. School closures exhibit the fastest and most widespread adoption, closely followed by event cancellations, with other policies showing slower adoption."
                            style="width:70%;" />
                        <figcaption>Adoption of school closure policies by governments worldwide. Data source: 
                            <a href="https://ourworldindata.org/coronavirus">Our World In Data</a>.</figcaption>
                    </figure>
                    <h2>International Policy Diffusion</h2>
                    <p>Global challenges hinge on international coordination of policy</p>
                    <p>COVID-19 lockdown: compelling example of almost unanimous global response</p>
                    <!--<p>Limitted research on policy diffusion focussing on international, rapid diffusion mechanisms and integration with simulation-based methods.</p>-->
                    <p>Aim: Develop a parsimonious ABM to explore mechanisms of international lockdown diffusion and 
                        improve prediction accuracy through <em>data assimilation</em>.</p>
                </section>
                
                
                <section id="PolicyDiffusion-Methods">
                    <h2>Methods</h2>
                    <p>Agent-Based Model (ABM)</p>
                    <p class="l2">Agents: <em>countries</em>, with binary lockdown states ("lockdown" or "not in lockdown").</p>
                    <p class="l2">Behaviour: Peer mimicry based on similarity (income, democracy index, geography).</p>
                    <p class="l2">Secondary mechanism: Autonomous lockdown adoption based on internal thresholds (e.g., population density).</p>
                    <p>Calibration</p>
                    <p class="l2">Based on real-world lockdown data (March 2020) and parameters like social thresholds, peer group size, and adoption probabilities.</p>
                    <p>Data assimilation with a particle filter</p>
                    <p class="l2">Updates model predictions in real time using observed data (e.g., lockdown status of countries).</p>
                    <p class="l2">Improves model alignment with real-world dynamics by filtering poorly performing simulations.</p>
                </section>
                
                <section id="PolicyDiffusion-Results">
                        <img class= "right"
                             data-src="../figures/paper_figures/2023-Covid_Policy_Response/fig4_5-vertical.png"
                             alt="“Two panels comparing the percentage of countries in lockdown predicted by the base model and particle filter. Top panel: Base model ensemble run with 100 simulations, showing the mean prediction (black line) closely following observed data (red dashed line) with wide confidence intervals. Bottom panel: Particle filter with 1000 particles, showing improved alignment with observed data and narrower confidence intervals compared to the base model."
                             style="width:35%"/>
                    <h2>Results</h2>
                    <p>After calibration, base model performance is adequate, but exhibits large variance, especially during 'critical' phase
                    (when most countries are going in to lockdown).</p>
                    <p>Macro performance better than macro performance</p>
                    <p class="l2">An accurate lockdown percentage doesn't mean the right countries are in lockdown</p>
                    <p>Particle filter narrows confidence intervals and reduces MSE by up to 75%; up to 40% in the critical phase</p>
                    <p class="l2">Performance during the critical few days is crucial if the model is going to be useful</p>
                </section>
            
                <!--
                <section id="PolicyDiffusion-Results2">
                    <img data-src="../figures/paper_figures/2023-Covid_Policy_Response/fig4_5.png"
                         style="width:60%"/>
                </section>
                -->
                
                <section id="PolicyDiffusion-Conclusions">
                    <h2>Conclusions</h2>
                    <h3>International Policy Diffusion</h3>
                    <p>Proof-of-concept: social / political A-B diffusion models can be combined 
                        with data assimilation.</p>
                    <p>Particle filter improves lockdown predictions, particularly in the 'critical phase'</p>
                    <p>But the model still incorrectly predicts many countries</p>
                    <p class="l2">Undoubtedly need a more nuanced model to improve predictions further
                        (beyond peer mimicry).</p>
                    
                </section>
                
                
                
                <!-- ************************************************************
                *********************** WealthDistributions **********************************
                ************************************************************ -->
                
                <section id="WealthDistributions" >
                    <figure class="right">
                        <img data-src="../figures/paper_figures/2025-ABM_Wealth_Distribution/cover.png"
                         alt="Cover image of the paper" />    
                        <figcaption style="font-size: small">Oswald, Y., K. Suchak, and N Malleson (2025). 
                        Agent-Based Models of the United States Wealth Distribution with Ensemble Kalman Filter. 
                        <i>Journal of Economic Behavior &amp; Organization</i> 229:106820. 
                        DOI: <a href="https://doi.org/10.1016/j.jebo.2024.106820">10.1016/j.jebo.2024.106820</a>
                        </figcaption>
                    </figure>
                    <h2>Case Study 3</h2>
                    <h3>Wealth Diffusion with an EnKF</h3>
                    <p>Significant wealth inequality in the U.S.</p>
                    <p class="l2">The top 1% hold ~35% of wealth, while the bottom 50% hold almost none.</p>
                    <p>(Near) real-time predictions are essential, particularly during crises</p>
                    <p>Paper explores the integration of ABMs with data assimilation to improve prediction accuracy.</p>
                </section>
                
                <section id="WealthDistributions-Context">
                    <h2>Wealth Diffusion: Context</h2>
                    
                    <figure>
                        <img data-src="../figures/paper_figures/2025-ABM_Wealth_Distribution/fig1.png"
                         alt="Wealth distribution among different wealth groups in the U.S. The 50% poorest people lost significant wealth during the 2008 financial crisis. The data are from https://realtimeinequality.org/ with details in Blanchet et al. (2022)." />
                        <figcaption>Wealth distribution in the U.S. D from <a href="https://realtimeinequality.org/">realtimeinequality.org</a> 
                            with details in Blanchet et al. (2022).</figcaption>
                    </figure>
                </section>
                
                <section id="WealthDistributions-Methods1">
                    <h2>Methods (i)</h2>
                    <h3>Wealth Diffusion with an EnKF</h3>
                    <p>Developed two agent-based models of U.S. wealth distribution:</p>
                    <p>Model 1:</p>
                    <p class="l2">Adapted from literature, focused on wealth accumulation through proportional allocation of growth.</p>
                    <p class="l2">Agents' wealth grows as a function of their initial wealth, reflecting the compounding effect of wealth.</p>
                    <p class="l2">Limited agent interaction; growth is largely independent of network effects.</p>
                    <p>Model 2:</p>
                    <p class="l2">Developed from scratch, includes network-based agent interactions and adaptive behaviours
                        (more akin to a '<em>true</em>' ABM)</p>
                    <!--<p class="l2">Wealth exchange occurs through trades with neighbours, influenced by agents' risk tolerance and network position.</p>
                    <p class="l2">Adaptive behavior: agents adjust their willingness-to-risk (WTR) based on trade outcomes, making them dynamic.</p>
                    <p class="l2">Captures non-linear dynamics and emergent patterns in wealth distribution.</p>-->
                </section>
                
                <section id="WealthDistributions-Methods2">
                    <img class="right" style="width: 20%;"
                         src="../figures/paper_figures/2025-ABM_Wealth_Distribution/fig3.png"
                        alt="Flowchart illustrating the particle filter process. It begins with generating an ensemble of models, followed by predictions. At each time step, the algorithm checks if filtering is required (t = k). If yes, the predictions are compared to observations, optimal synthesis is computed, and ensemble members are updated. The process repeats for subsequent time steps." />
                    <h2>Methods (ii)</h2>
                    <h3>Wealth Diffusion with an EnKF</h3>
                    <p>Integrated the ABMs with an Ensemble Kalman Filter (EnKF):</p>
                    <p class="l2">EnKF adjusted agent-specific variables (e.g., wealth per agent) dynamically to match observed data.</p>
                    <p>Calibrated to U.S. wealth data (1990–2022) and tested them against real-time wealth estimates.</p>
                </section>
                
                
                <section id="WealthDistributions-Results">
                    <img data-src="../figures/paper_figures/2025-ABM_Wealth_Distribution/fig4.png"
                         alt="Results of Experiment 1 Part A: illustrating the error of models 1 and 2 under Ensemble Kalman Filter (EnKF) optimisation with 100 ensemble members compared to the real data. The filter is applied every 20 time steps (months). Panels (A–D) depict the wealth share of the different economic groups (top 1%, top 10%–1%, middle 40%, bottom 50%) over time. Panels (A) and (B) present the archetypal behaviour of a single model run, illustrating how the EnKF influences the model behaviour. Panels (C) and (D) show the mean EnKF prediction and uncertainty across all ensemble members. Panel (E) depicts the Mean Absolute Error (MAE) from Eq. (7) of the two models, with and without the EnKF. It is clear that"
                         class="right"
                         style="width:60%;"
                    />
                    <h2>Results</h2>
                    <p>EnKF improved model accuracy significantly (20–50% error reduction).</p>
                    <p>Corrected disparities in predicted wealth shares for different economic groups (<em>observe the jagged lines</em>).</p>
                    <p>Filter still exhibited some unexpected behaviour</p>
                </section>
                
                <section id="WealthDistributions-Discussion">
                    <img class="right" src="../figures/paper_figures/2025-ABM_Wealth_Distribution/paper_chatgpt_image.jpg"
                         alt="Image to liven up slide showing abstract people and a network"
                         style="width: 30%"
                         />
                    <h2>Conclusions</h2>
                    <h3>Wealth Diffusion with an EnKF</h3>
                    <p>We show that a marco-economic ABM can be optimised with an EnKF</p>
                    <p class="l2">Improved short-term predictions, especially during a crisis</p>
                    <p class="l2">Essential during crises; models cannot include everything</p>
                    <p>Additional opportunity for improved <em>understanding</em></p>
                    <p class="l2">E.g. through examining evolution of the Kalman Gain matrix and contrasting the
                    observation v.s. model weights -- which become more or less certain over time?</p>
                </section>
                
                
                
                
                
                
                 <!-- ************************************************************
                    ************************* LLM / ABMs  ************************
                    ************************************************************ --> 
                <section id="fm-llms0" data-background-image="../figures/desert-jared-evans-Wwg1TzCuV9E-unsplash.jpg">
                    
                    <div class="fragment whitebackground">
                        <h2>For desert:</h2>
                        <h3>Foundation models and large-language models to drive agent behaviour</h3>
                    </div>
                    
                </section>
                
                
                <section id="fm-llms">
                    <h2>Foundation-model-backed ABMs</h2>
                    <p>Modelling human behaviour in ABMs is (still!) an ongoing challenge</p>
                    <p>Behaviour typically implemented with bespoke rules, but even more advanced mathematical approaches are limited</p>
                    <p>Can new AI approaches offer a solution?</p>
                    <p class="l2"><strong>Large Language Models</strong> can respond to prompts in 'believable', 'human-like' ways</p>
                    <p class="l2"><strong>Geospatial Foundation Models</strong> capture nuanced, complex associations between spatial objects</p>
                    <p class="l2"><strong>Multi-modal Foundation Models</strong> operate with diverse data (text, video, audio, etc.)</p>                    
                </section>
                
                
                <section id="flexible_behaviour" data-background-image="../figures/the-roaming-platypus-310824-unsplash-small.jpg">
                    <div class="whitebackground">
                        
                            <h2>Where might this lead...</h2>
                        
                        <div class="fragment">
                            <p>"All models are great, until you need them"</p>
                        </div>
                        <div class="fragment">
                            <p>It's fine to use models under normal conditions. Very useful.</p>
                        </div>
                        <div class="fragment">
                            <p>Especially if the system undergoes a fundamental change (COVID? Global financial crash?) -- 
                                then we <strong>really</strong> need models to help</p>
                        </div>
                        <div class="fragment">
                            <p>But then they become totally useless!</p>
                        </div>
                    </div>
                </section>
    
                
                <section id="flexible_behaviour3" data-background-image="../figures/the-roaming-platypus-310824-unsplash-small.jpg">
                    <h2>&nbsp;</h2>
                    <div class="whitebackground">
                        <h2>Foundation-model-backed ABMs</h2>
                        <p>Maybe a model with LLM-backed agents would be 
                            better able to respond after a catastrophic system change</p>
                        <img data-src="../figures/llm_agents.png" style="width:70%;" 
                             alt="Diagram showing traditional ABM v.s. one where the agents are controlled by LLMs"/>
                    </div>
                </section>
                
                
                
                
                <section id="llms">
                    <h2>Large Language Models (LLMs)</h2>
                    <p>Early evidence suggests that large-language models (LLMs) can be used to represent a wide range 
                        of human behaviours</p>
                    <p>Already a flurry of activity in LLM-backed ABMs</p>
                    <p class="l2">E.g. AutoGPT, BabyAGI, Generative Agents, MetaGP ... and others ... </p>
                    <figure>
                        <img src="../figures/attribution/park_llm_agent.png"
                             style="width:50%;"
                             alt="Image of the ABM created by Park et. al."
                             />
                        <figcaption>Park, Joon Sung, Joseph O’Brien, Carrie Jun Cai, Meredith Ringel Morris, Percy Liang, and Michael S. Bernstein. 2023. 
                            ‘Generative Agents: Interactive Simulacra of Human Behavior’. In Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology, 1–22. San Francisco CA USA: ACM. 
                            DOI: <a href="https://doi.org/10.1145/3586183.3606763">10.1145/3586183.3606763</a>.
                        </figcaption>
                    
                    </figure>
                    
                </section>
                
                
                <section id="llm_abm_challenges">
                    <h2>LLMs &amp; ABMs: Challenges</h2>
                    <p>Lots of them!</p>
                    <p class="l2">Computational complexity: thousands/millions of LLMs?</p>
                    <p class="l2">Bias: LLMs very unlikely to be representative 
                        (non-English speakers, cultural bias, digital divide, etc.)</p>
                    <p class="l2">Validation: consistency (i.e. stochasticity), robustness (i.e. sensitivity to prompts),
                        hallucinations, train/test contamination, and others</p>
                    <p>Main one for this talk: <strong>the need to interface through text</strong></p>
                    <p class="l2">Communicating -- and maybe reasoning -- with language makes sense</p>
                    <p class="l2">But having to <i>describe</i> the world with text is a huge simplification /
                        abstraction </p>
                </section>
                
                
                <section id="fms">
                    <h2>A solution? Multi-modal and Geospatial Foundation Models</h2>
                    <p>Foundation models: "a machine learning or deep learning model trained on vast datasets so that 
                        it can be applied across a wide range of use cases" (Wikipedia)</p>
                    <p class="l2">LLMs are Foundation models that work with text</p>
                    <p>Geospatial Foundation Models</p>
                    <p class="l2">FMs that work with spatial data (street view images, geotagged social media data, 
                        video, GPS trajectories, points-of-interest, etc.) to create rich, multidimensional spatial
                        representations </p>
                    <p>Multi-modal Foundation Models</p>
                    <p class="l2">FMs that work with diverse data, e.g. text, audio, image, video, etc.</p>
                </section>
                
                <!--<section id="gfms">
                    <h2>Geospatial Foundation Model Example</h2>
                    <p>Example of a foundation model constructed using OSM data</p>
                    <p class="l2">Embeddings are remarkably good at predicting things like traffic speed and 
                        building functionality (zero-shot)</p>
                    <figure>
                        <img src="../figures/attribution/huang_urbanclip.png"
						style="width:70%;">
                        <figcaption>Balsebre, Pasquale, Weiming Huang, Gao Cong, and Yi Li. 2024. ‘City Foundation Models for Learning General Purpose Representations from OpenStreetMap’. 
                            In Proceedings of the 33rd ACM International Conference on Information and Knowledge Management, 87–97. Boise ID USA: ACM..
                            DOI: <a href="https://doi.org/10.1145/3627673.3679662">10.1145/3627673.3679662</a>
                        </figcaption>
                    </figure>
                </section>  -->
                
                <!-- Weiming land use estimation not quite relevantZ
                <section id="gfms">
                    <h2>Geospatial Foundation Model Example</h2>
                    <p>Huang et al. develop a prompting strategy that allows a vision-language model (CLIP) identify
                    land use in street view data by <i>comparing text and image embeddings</i></p>
                    <figure>
                        <img src="../figures/attribution/huang_urbanclip.jpg">
                        <figcaption>Huang, Weiming, Jing Wang, and Gao Cong. 2024. ‘Zero-Shot Urban Function Inference with Street View Images through Prompting a Pretrained Vision-Language Model’. 
                            <i>International Journal of Geographical Information Science</i> 38 (7): 1414–42. 
                            DOI: <a href="https://doi.org/10.1080/13658816.2024.2347322">10.1080/13658816.2024.2347322</a>.
                        </figcaption>
                    </figure>
                    
                </section> 
                -->

                <section id="towards">
                    <h2>Towards Multi-Modal Foundation Models for ABMs (??)</h2>
                    <p>GFMs and LLMs: a new generation of ABMs?</p>
                    <p class="l2">LLMs 'understand' human behaviour and can reason realistically</p>
                    <p class="l2">GFMs provide nuanced representation of 'space'</p>
                    <div class="fragment">
                        <p>How?</p>
                        <p class="l2"><strike>I've no idea!</strike> Watch this space.</p>
                        <p class="l2">Insert spatial embeddings directly into the LLM?</p>
                        <p class="l2">Use an approach like BLIP-2 that trains a small transformer as an
                        interface between an LLM and a vision-language model</p>
                        <p class="l2">Suggestions welcome!</p>
                    </div>
                </section>
                
                
                <!-- ************************************************************
                ************** CONCLUSION / ACKNOWLEDGEMENTS ********************
                ************************************************************ -->
                
                
                
                <section id="summary">
                    <img class="right"
                         src="../figures/chatgpt/digital_city_abm.png"
                         alt="Conceptual LLM ABM city image, from chatgpt" />
                    <h2>Summary</h2>
                    <p>ABC: dyncmic calibration and inferring latent parameters</p>
                    <p>Data assimilation for ABMs: Ensemble Kalman Filter worked best</p>
                    <p>LLMs and foundation models for ABMs! </p>
                </section>
                


                <section class="title" id="thanks"
                         data-background-video="../videos/city_night.mp4"
                         data-background-video-loop="loop">
                    <div class="whitebackground2">
                        <h5>Calibration of Agent-Based Models. 11th July 2025, Cambridge.</h5>
                        <hr />
                        <h1 style="font-size: 45px;">Data Assimilation for Agent-Based Models<br/> 
                            <div style="font-size: 35px;">(With a sprinkling of ABC and LLMs)</div></h1>
                        <hr />
                        <h2 style="font-size: 25px;">
                            <a href="http://nickmalleson.co.uk/">Nick Malleson</a>, University of Leeds, UK</h2>
                        <!--<h4><a href="mailto:n.s.malleson@leeds.ac.uk">n.s.malleson@leeds.ac.uk</a>-->
                        <!--<h4><a href="http://dust.leeds.ac.uk">dust.leeds.ac.uk</a></h4>-->
                        <hr />
                        <p style="text-align:center;font-size:20px">Slides available at: <br />
                            <a href="https://urban-analytics.github.io/dust/presentations.html">https://urban-analytics.github.io/dust/presentations.html</a>
                        </p>
                        <hr />
                        <a href="https://europa.eu/european-union/index_en">
                            <img style="float:left;padding:5px;width:auto; height:60px;"
                                 data-src="../figures/LOGO_EU.jpg" />
                        </a>
                        <a href="http://www.leeds.ac.uk/">
                            <img style="float:right;padding:5px;width:auto; height:60px;"
                                 data-src="../figures/uol_logo.gif" />
                        </a>
                        <!--<a href="https://environment.leeds.ac.uk/geography">
<img style="float:right;padding:10px;width:150px; height:auto;" data-src="../figures/LOGO_SOG.png" />
</a>-->
                        <!-- <a href="http://www.turing.ac.uk/">
<img style="float:right;padding:10px;width:150px; height:auto;" src="../figures/LOGO_TURING.png"/>
</a> -->
                    </div>
                </section>









            </div>
        </div>

        <script src="reveal/lib/js/head.min.js"></script>
        <script src="reveal/js/reveal.js"></script>

        <script>
            // More info https://github.com/hakimel/reveal.js#configuration
            Reveal.initialize({
                history: true,

                // More info https://github.com/hakimel/reveal.js#dependencies
                dependencies: [
                    { src: 'reveal/plugin/markdown/marked.js' },
                    { src: 'reveal/plugin/markdown/markdown.js' },
                    { src: 'reveal/plugin/notes/notes.js', async: true },
                    { src: 'reveal/plugin/highlight/highlight.js', async: true, callback: function () { hljs.initHighlightingOnLoad(); } }
                ]
            });
        </script>
    </body>

</html>
